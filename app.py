import streamlit as st
import pandas as pd
import numpy as np
import os
from sentence_transformers import SentenceTransformer, util

st.set_page_config(
    page_title="üé¨ –ù–µ–π—Ä–æ–ø–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤",
    page_icon="üß†",
    layout="centered"
)

st.title("üß† –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø–æ–∏—Å–∫ —Ñ–∏–ª—å–º–æ–≤ –ø–æ —Å–º—ã—Å–ª—É")
st.markdown(
    "–û–ø–∏—à–∏—Ç–µ —Å—é–∂–µ—Ç ‚Äî –º—ã –Ω–∞–π–¥—ë–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–∏–ª—å–º—ã."
    "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫–∏."
)

@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

@st.cache_data
def load_data_and_embeddings():
    if not os.path.exists("movies_simple.csv"):
        st.error("‚ùå –§–∞–π–ª 'movies_simple.csv' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        st.stop()
    if not os.path.exists("movie_embeddings.npy"):
        st.error("‚ùå –§–∞–π–ª 'movie_embeddings.npy' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.")
        st.stop()

    df = pd.read_csv("movies_simple.csv")
    embeddings = np.load("movie_embeddings.npy")
    return df, embeddings

try:
    model = load_model()
    df, embeddings = load_data_and_embeddings()
except Exception as e:
    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}")
    st.stop()

def neural_search(query, df, embeddings, model, top_k=10, year_from=1900, year_to=2025, min_sim=0.1):
    if not query.strip():
        return pd.DataFrame()

    mask = (df['year'] >= year_from) & (df['year'] <= year_to)
    filtered_df = df[mask]
    if filtered_df.empty:
        return pd.DataFrame()

    indices = filtered_df.index.tolist()
    filtered_embs = embeddings[indices]

    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å..."):
        query_emb = model.encode(query, convert_to_tensor=True)
        sims = util.cos_sim(query_emb, filtered_embs)[0].cpu().numpy()

    top_idx = np.argsort(sims)[::-1]
    results = []
    for i in top_idx:
        if sims[i] < min_sim or len(results) >= top_k:
            break
        orig_idx = indices[i]
        year = df.loc[orig_idx, 'year']
        year_display = int(year) if pd.notna(year) and year > 0 else "???"
        results.append({
            'title': df.loc[orig_idx, 'title'],
            'overview': df.loc[orig_idx, 'overview'],
            'year': year_display,
            'similarity': float(sims[i])
        })
    return pd.DataFrame(results)

query = st.text_area(
    "üîç –û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞",
    placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: ¬´–¥–µ–≤—É—à–∫–∞ —Ç–µ—Ä—è–µ—Ç –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ –∞–≤–∞—Ä–∏–∏, –Ω–æ –µ—ë –ø—Ä–µ—Å–ª–µ–¥—É—é—Ç —Å–Ω—ã –æ –∫–æ—Å–º–æ—Å–µ¬ª",
    height=100
)

col1, col2 = st.columns(2)
with col1:
    year_from = st.number_input("–ì–æ–¥ –æ—Ç", min_value=1900, max_value=2025, value=1900)
with col2:
    year_to = st.number_input("–ì–æ–¥ –¥–æ", min_value=1900, max_value=2025, value=2025)

if st.button("üé¨ –ù–∞–π—Ç–∏ —Ñ–∏–ª—å–º—ã"):
    if not query.strip():
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞.")
    else:
        with st.spinner("–ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–∏–ª—å–º—ã..."):
            results = neural_search(
                query=query,
                df=df,
                embeddings=embeddings,
                model=model,
                top_k=8,
                year_from=year_from,
                year_to=year_to,
                min_sim=0.1
            )

        if results.empty:
            st.info("üì≠ –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –ª–µ—Ç.")
        else:
            st.subheader(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ñ–∏–ª—å–º–æ–≤")
            for _, r in results.iterrows():
                st.markdown(f"### üé• {r['title']} ({r['year']})")
                st.markdown(f"**–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å**: `{r['similarity']:.3f}`")
                st.write(r['overview'])
                st.markdown("---")

with st.expander("üí° –ü—Ä–∏–º–µ—Ä—ã —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"):
    st.write("""
    - *–∞–≥–µ–Ω—Ç 007 —Ä–∞—Å—Å–ª–µ–¥—É–µ—Ç –∑–∞–≥–æ–≤–æ—Ä, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –ò–ò*
    - *–ª—é–±–æ–≤—å –º–µ–∂–¥—É —á–µ–ª–æ–≤–µ–∫–æ–º –∏ —Ä–æ–±–æ—Ç–æ–º –≤ –¢–æ–∫–∏–æ –±—É–¥—É—â–µ–≥–æ*
    - *–ø–∏—Ä–∞—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç –∫–∞—Ä—Ç—É —Å–æ–∫—Ä–æ–≤–∏—â –Ω–∞ –∑–∞—Ç–æ–Ω—É–≤—à–µ–º –∫–æ—Ä–∞–±–ª–µ*
    - *–∂–µ–Ω—â–∏–Ω–∞ –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —á–∏—Ç–∞—Ç—å –º—ã—Å–ª–∏ –∏ —Ä–∞—Å–∫–∞–∏–≤–∞–µ—Ç—Å—è*
    - *–≤—ã–∂–∏–≤—à–∏–µ –ø–æ—Å–ª–µ –∞–ø–æ–∫–∞–ª–∏–ø—Å–∏—Å–∞ –∏—â—É—Ç —á–∏—Å—Ç—É—é –≤–æ–¥—É –≤ –ø—É—Å—Ç—ã–Ω–µ*
    """)